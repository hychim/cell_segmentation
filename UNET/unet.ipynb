{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2064dbb6",
   "metadata": {},
   "source": [
    "# Unet"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f6cf1d2-cb78-47e5-bc80-25c3491c3d19",
   "metadata": {},
   "source": [
    "https://amaarora.github.io/2020/09/13/unet.html\n",
    "https://towardsdev.com/original-u-net-in-pytorch-ebe7bb705cc7\n",
    "https://towardsdatascience.com/why-adamw-matters-736223f31b5d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f5a061-0e50-4c4b-9294-1340a95283f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from torchmetrics import Accuracy\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a07e780-234b-4093-a799-b0112e794ec4",
   "metadata": {},
   "source": [
    "# Model\n",
    "- https://www.kaggle.com/code/hychim/unet-segmentation-on-carvana-dataset/edit\n",
    "- https://amaarora.github.io/2020/09/13/unet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c0e4669-fec1-4d2b-811b-c970cc6c1c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(pl.LightningModule):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias= False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias= False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNET(pl.LightningModule):\n",
    "    def __init__(self, in_channels=3, out_channels=1, features=[64,128,256,512], learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.features= features\n",
    "        \n",
    "        # for logging\n",
    "        self.train_acc = Accuracy()\n",
    "        self.valid_acc = Accuracy()\n",
    "        self.test_acc = Accuracy()\n",
    "        \n",
    "        self.down = nn.ModuleList()\n",
    "        self.up = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        for feature in features:\n",
    "            self.down.append(Block(in_channels, feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        self.middle_block = Block(features[-1], features[-1]*2)\n",
    "\n",
    "        for feature in reversed(features):\n",
    "            self.up.append(nn.ConvTranspose2d(feature*2, feature, 2, 2))\n",
    "            self.up.append(Block(feature*2, feature) )                      # x gets concat to 2xchannel\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        concats = [] \n",
    "\n",
    "        for down in self.down:\n",
    "            x = down(x)\n",
    "            concats.append(x)\n",
    "            x = self.pool(x)  # Max pooling (encoding features into lower dimension tensor)\n",
    "        \n",
    "        concats = concats[::-1] # reverse the whole concat list for concatenation in the up layer \n",
    "        x = self.middle_block(x)\n",
    "        \n",
    "        # self up structure\n",
    "        # (0)upconv\n",
    "        # (1)Block\n",
    "        # ...\n",
    "        for idx in range(len(self.up)):\n",
    "            x = self.up[idx](x)\n",
    "            concat = concats[idx]\n",
    "            if concat != x.shape:\n",
    "                concat = transforms.functional.resize(concat, size=x.shape[2:])\n",
    "            x = torch.cat((concat, x), dim=1)\n",
    "            x = self.up[idx+1](x)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "\n",
    "        return(x)\n",
    "    \n",
    "    def trainning_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = nn.functional.cross_entropy(logits, y) # or use BCEWithLogitsLoss() for soft label?\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.train_acc.update(preds, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = nn.functional.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.valid_acc.update(preds, y)\n",
    "        self.log(\"valid_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dc10d96-d616-4e17-a703-4ec6a663302b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   | Name                | Type            | Params\n",
       "---------------------------------------------------------\n",
       "0  | train_acc           | Accuracy        | 0     \n",
       "1  | valid_acc           | Accuracy        | 0     \n",
       "2  | test_acc            | Accuracy        | 0     \n",
       "3  | down                | ModuleList      | 4.7 M \n",
       "4  | down.0              | Block           | 38.8 K\n",
       "5  | down.0.conv         | Sequential      | 38.8 K\n",
       "6  | down.0.conv.0       | Conv2d          | 1.7 K \n",
       "7  | down.0.conv.1       | BatchNorm2d     | 128   \n",
       "8  | down.0.conv.2       | ReLU            | 0     \n",
       "9  | down.0.conv.3       | Conv2d          | 36.9 K\n",
       "10 | down.0.conv.4       | BatchNorm2d     | 128   \n",
       "11 | down.0.conv.5       | ReLU            | 0     \n",
       "12 | down.1              | Block           | 221 K \n",
       "13 | down.1.conv         | Sequential      | 221 K \n",
       "14 | down.1.conv.0       | Conv2d          | 73.7 K\n",
       "15 | down.1.conv.1       | BatchNorm2d     | 256   \n",
       "16 | down.1.conv.2       | ReLU            | 0     \n",
       "17 | down.1.conv.3       | Conv2d          | 147 K \n",
       "18 | down.1.conv.4       | BatchNorm2d     | 256   \n",
       "19 | down.1.conv.5       | ReLU            | 0     \n",
       "20 | down.2              | Block           | 885 K \n",
       "21 | down.2.conv         | Sequential      | 885 K \n",
       "22 | down.2.conv.0       | Conv2d          | 294 K \n",
       "23 | down.2.conv.1       | BatchNorm2d     | 512   \n",
       "24 | down.2.conv.2       | ReLU            | 0     \n",
       "25 | down.2.conv.3       | Conv2d          | 589 K \n",
       "26 | down.2.conv.4       | BatchNorm2d     | 512   \n",
       "27 | down.2.conv.5       | ReLU            | 0     \n",
       "28 | down.3              | Block           | 3.5 M \n",
       "29 | down.3.conv         | Sequential      | 3.5 M \n",
       "30 | down.3.conv.0       | Conv2d          | 1.2 M \n",
       "31 | down.3.conv.1       | BatchNorm2d     | 1.0 K \n",
       "32 | down.3.conv.2       | ReLU            | 0     \n",
       "33 | down.3.conv.3       | Conv2d          | 2.4 M \n",
       "34 | down.3.conv.4       | BatchNorm2d     | 1.0 K \n",
       "35 | down.3.conv.5       | ReLU            | 0     \n",
       "36 | up                  | ModuleList      | 12.2 M\n",
       "37 | up.0                | ConvTranspose2d | 2.1 M \n",
       "38 | up.1                | Block           | 7.1 M \n",
       "39 | up.1.conv           | Sequential      | 7.1 M \n",
       "40 | up.1.conv.0         | Conv2d          | 4.7 M \n",
       "41 | up.1.conv.1         | BatchNorm2d     | 1.0 K \n",
       "42 | up.1.conv.2         | ReLU            | 0     \n",
       "43 | up.1.conv.3         | Conv2d          | 2.4 M \n",
       "44 | up.1.conv.4         | BatchNorm2d     | 1.0 K \n",
       "45 | up.1.conv.5         | ReLU            | 0     \n",
       "46 | up.2                | ConvTranspose2d | 524 K \n",
       "47 | up.3                | Block           | 1.8 M \n",
       "48 | up.3.conv           | Sequential      | 1.8 M \n",
       "49 | up.3.conv.0         | Conv2d          | 1.2 M \n",
       "50 | up.3.conv.1         | BatchNorm2d     | 512   \n",
       "51 | up.3.conv.2         | ReLU            | 0     \n",
       "52 | up.3.conv.3         | Conv2d          | 589 K \n",
       "53 | up.3.conv.4         | BatchNorm2d     | 512   \n",
       "54 | up.3.conv.5         | ReLU            | 0     \n",
       "55 | up.4                | ConvTranspose2d | 131 K \n",
       "56 | up.5                | Block           | 442 K \n",
       "57 | up.5.conv           | Sequential      | 442 K \n",
       "58 | up.5.conv.0         | Conv2d          | 294 K \n",
       "59 | up.5.conv.1         | BatchNorm2d     | 256   \n",
       "60 | up.5.conv.2         | ReLU            | 0     \n",
       "61 | up.5.conv.3         | Conv2d          | 147 K \n",
       "62 | up.5.conv.4         | BatchNorm2d     | 256   \n",
       "63 | up.5.conv.5         | ReLU            | 0     \n",
       "64 | up.6                | ConvTranspose2d | 32.8 K\n",
       "65 | up.7                | Block           | 110 K \n",
       "66 | up.7.conv           | Sequential      | 110 K \n",
       "67 | up.7.conv.0         | Conv2d          | 73.7 K\n",
       "68 | up.7.conv.1         | BatchNorm2d     | 128   \n",
       "69 | up.7.conv.2         | ReLU            | 0     \n",
       "70 | up.7.conv.3         | Conv2d          | 36.9 K\n",
       "71 | up.7.conv.4         | BatchNorm2d     | 128   \n",
       "72 | up.7.conv.5         | ReLU            | 0     \n",
       "73 | pool                | MaxPool2d       | 0     \n",
       "74 | middle_block        | Block           | 14.2 M\n",
       "75 | middle_block.conv   | Sequential      | 14.2 M\n",
       "76 | middle_block.conv.0 | Conv2d          | 4.7 M \n",
       "77 | middle_block.conv.1 | BatchNorm2d     | 2.0 K \n",
       "78 | middle_block.conv.2 | ReLU            | 0     \n",
       "79 | middle_block.conv.3 | Conv2d          | 9.4 M \n",
       "80 | middle_block.conv.4 | BatchNorm2d     | 2.0 K \n",
       "81 | middle_block.conv.5 | ReLU            | 0     \n",
       "82 | final_conv          | Conv2d          | 65    \n",
       "---------------------------------------------------------\n",
       "31.0 M    Trainable params\n",
       "0         Non-trainable params\n",
       "31.0 M    Total params\n",
       "124.151   Total estimated model params size (MB)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.utilities.model_summary.summarize(UNET(), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c3c94e-24b2-470c-a8db-093dfd8d2c00",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae62e9e8-075a-48f3-8837-74df7bea018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, image_path, mask_path, transforms):\n",
    "    self.images = glob.glob(os.path.join(image_path, '*.jpg'))\n",
    "    self.image_path = image_path\n",
    "    self.mask_path = mask_path\n",
    "    self.transforms = transforms\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.images)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    img = np.array(Image.open(self.images[idx]).convert('RGB'))\n",
    "    mask = np.array(Image.open(os.path.join(self.mask_path, os.path.basename(self.images[idx]).replace('.jpg', '.png')))) \n",
    "    mask[mask == 255.0] = 1.0  \n",
    "    augmentations = self.transforms(image=img, mask=mask)\n",
    "    image = augmentations[\"image\"]\n",
    "    mask = augmentations[\"mask\"]\n",
    "    mask = torch.unsqueeze(mask, 0)\n",
    "    mask = mask.type(torch.float32)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b1822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, image_path, mask_path, transform, train_size=0.90, batch_size: int = 9):\n",
    "        super().__init__()\n",
    "        self.image_path = image_path\n",
    "        self.mask_path = mask_path\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transform\n",
    "        self.train_size = train_size\n",
    "        \n",
    "    def setup(self, stage = None):\n",
    "        if stage in (None, 'fit'):\n",
    "            ds = SegmentationDataset(self.image_path, self.mask_path, self.transform)\n",
    "            train_size = math.floor(len(ds)*self.train_size)\n",
    "            val_size = len(ds)-train_size\n",
    "            train_ds, val_ds = torch.utils.data.random_split(ds, [train_size, val_size])\n",
    "            self.train_dataset = train_ds\n",
    "            self.val_dataset = val_ds\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, self.batch_size, num_workers=2, shuffle=True, persistent_workers=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, self.batch_size, num_workers=2, persistent_workers=True)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, self.batch_size)\n",
    "\n",
    "mnist_dm = SegmentationDataModule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89aa2c6-644e-4dc4-a0df-0df77ff225af",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e12a78f-cdf3-4072-928d-4e489df78a86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
